{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataset for @HOME2024 using GroundingDino and SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageEnhance, ImageFilter, ImageFont\n",
    "from pycocotools import mask\n",
    "import json\n",
    "import yaml\n",
    "import csv\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import ultralytics\n",
    "import time\n",
    "import imutils\n",
    "import argparse\n",
    "\n",
    "#grounding imports----------------\n",
    "\n",
    "import groundingdino.datasets.transforms as T\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util import box_ops\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict, get_phrases_from_posmap\n",
    "from groundingdino.util.vl_utils import create_positive_map_from_span\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize images in a folder to a specific size\n",
    "\n",
    "pathtofiles = \"/home/jabv/Desktop/bolsas/\"\n",
    "pathtoimage = [f.path for f in os.scandir(pathtofiles) if f.is_dir()]\n",
    "size = 720\n",
    "\n",
    "#pathtoimage = os.listdir(pathtofiles)\n",
    "\n",
    "for filepath in pathtoimage:\n",
    "    folder = filepath + \"/\"\n",
    "    for filename in os.listdir(folder):\n",
    "        img = Image.open(folder + filename)\n",
    "        img = img.resize((size, size))\n",
    "        img.save(folder + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto label con Segment anyting y modelo de YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IMG_4947.png', 'IMG_4936.png', 'IMG_4638.png', 'IMG_4563.png', 'IMG_4948.png', 'IMG_4926.png', 'IMG_4966.png', 'IMG_4610.png', 'IMG_4572.png', 'IMG_4953.png', 'IMG_4962.png', 'IMG_4559.png', 'IMG_4883.png', 'IMG_4637.png', 'IMG_4920.png', 'IMG_4579.png', 'IMG_4560.png', 'IMG_4557.png', 'IMG_4574.png', 'IMG_4886.png', 'IMG_4967.png', 'IMG_4631.png', 'IMG_4937.png', 'IMG_4545.png', 'IMG_4969.png', 'IMG_4944.png', 'IMG_4605.png', 'IMG_4873.png', 'IMG_4951.png', 'IMG_4613.png', 'IMG_4548.png', 'IMG_4974.png', 'IMG_4941.png', 'IMG_4589.png', 'IMG_4614.png', 'IMG_4931.png', 'IMG_4907.png', 'IMG_4914.png', 'IMG_4655.png', 'IMG_4906.png', 'IMG_4599.png', 'IMG_4970.png', 'IMG_4587.png', 'IMG_4542.png', 'IMG_4896.png', 'IMG_4956.png', 'IMG_4630.png', 'IMG_4583.png', 'IMG_4938.png', 'IMG_4913.png', 'IMG_4633.png', 'IMG_4977.png', 'IMG_4904.png', 'IMG_4573.png', 'IMG_4881.png', 'IMG_4540.png', 'IMG_4901.png', 'IMG_4624.png', 'IMG_4628.png', 'IMG_4909.png', 'IMG_4618.png', 'IMG_4983.png', 'IMG_4578.png', 'IMG_4885.png', 'IMG_4611.png', 'IMG_4884.png', 'IMG_4620.png', 'IMG_4968.png', 'IMG_4650.png', 'IMG_4897.png', 'IMG_4959.png', 'IMG_4876.png', 'IMG_4949.png', 'IMG_4911.png', 'IMG_4550.png', 'IMG_4654.png', 'IMG_4984.png', 'IMG_4536.png', 'IMG_4565.png', 'IMG_4950.png', 'IMG_4952.png', 'IMG_4889.png', 'IMG_4585.png', 'IMG_4933.png', 'IMG_4596.png', 'IMG_4922.png', 'IMG_4965.png', 'IMG_4932.png', 'IMG_4644.png', 'IMG_4900.png', 'IMG_4649.png', 'IMG_4890.png', 'IMG_4609.png', 'IMG_4604.png', 'IMG_4543.png', 'IMG_4544.png', 'IMG_4567.png', 'IMG_4561.png', 'IMG_4930.png', 'IMG_4899.png', 'IMG_4566.png', 'IMG_4928.png', 'IMG_4929.png', 'IMG_4597.png', 'IMG_4880.png', 'IMG_4892.png', 'IMG_4603.png', 'IMG_4918.png', 'IMG_4586.png', 'IMG_4924.png', 'IMG_4591.png', 'IMG_4651.png', 'IMG_4877.png', 'IMG_4602.png', 'IMG_4916.png', 'IMG_4975.png', 'IMG_4878.png', 'IMG_4546.png', 'IMG_4621.png', 'IMG_4925.png', 'IMG_4954.png', 'IMG_4568.png', 'IMG_4598.png', 'IMG_4537.png', 'IMG_4982.png', 'IMG_4639.png', 'IMG_4592.png', 'IMG_4891.png', 'IMG_4898.png', 'IMG_4594.png', 'IMG_4562.png', 'IMG_4645.png', 'IMG_4623.png', 'IMG_4635.png', 'IMG_4640.png', 'IMG_4629.png', 'IMG_4595.png', 'IMG_4923.png', 'IMG_4964.png', 'IMG_4903.png', 'IMG_4590.png', 'IMG_4976.png', 'IMG_4945.png', 'IMG_4606.png', 'IMG_4616.png', 'IMG_4634.png', 'IMG_4648.png', 'IMG_4908.png', 'IMG_4636.png', 'IMG_4943.png', 'IMG_4934.png', 'IMG_4915.png', 'IMG_4935.png', 'IMG_4622.png', 'IMG_4577.png', 'IMG_4946.png', 'IMG_4963.png', 'IMG_4570.png', 'IMG_4607.png', 'IMG_4905.png', 'IMG_4538.png', 'IMG_4549.png', 'IMG_4541.png', 'IMG_4615.png', 'IMG_4927.png', 'IMG_4558.png', 'IMG_4887.png', 'IMG_4619.png', 'IMG_4971.png', 'IMG_4902.png', 'IMG_4981.png', 'IMG_4939.png', 'IMG_4612.png', 'IMG_4571.png', 'IMG_4910.png', 'IMG_4882.png', 'IMG_4564.png', 'IMG_4641.png', 'IMG_4979.png', 'IMG_4535.png', 'IMG_4653.png', 'IMG_4917.png', 'IMG_4955.png', 'IMG_4888.png', 'IMG_4874.png', 'IMG_4895.png', 'IMG_4919.png', 'IMG_4643.png', 'IMG_4534.png', 'IMG_4576.png', 'IMG_4940.png', 'IMG_4601.png', 'IMG_4646.png', 'IMG_4581.png', 'IMG_4593.png', 'IMG_4980.png', 'IMG_4625.png', 'IMG_4632.png', 'IMG_4973.png', 'IMG_4879.png', 'IMG_4547.png', 'IMG_4627.png', 'IMG_4972.png', 'IMG_4942.png', 'IMG_4588.png', 'IMG_4580.png', 'IMG_4912.png', 'IMG_4875.png', 'IMG_4957.png', 'IMG_4921.png', 'IMG_4617.png', 'IMG_4600.png', 'IMG_4539.png', 'IMG_4893.png', 'IMG_4608.png', 'IMG_4961.png', 'IMG_4575.png', 'IMG_4958.png', 'IMG_4647.png', 'IMG_4978.png', 'IMG_4894.png', 'IMG_4626.png', 'IMG_4582.png', 'IMG_4652.png', 'IMG_4569.png', 'IMG_4642.png']\n",
      "Processing image: IMG_4947.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabv/.local/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabv/.local/lib/python3.8/site-packages/transformers/modeling_utils.py:962: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/jabv/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 253, 1031, 2375, 2702\n",
      "Bounding box: 244, 1024, 2781, 2702\n",
      "File already exists, saving with _1\n",
      "Bounding box: 1070, 1471, 1849, 2212\n",
      "File already exists, saving with _2\n",
      "Processing image: IMG_4936.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jabv/.local/lib/python3.8/site-packages/transformers/modeling_utils.py:962: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/home/jabv/.local/lib/python3.8/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 914, 582, 2742, 2831\n",
      "Bounding box: 1376, 1485, 2061, 2153\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4638.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1360, 414, 2691, 2372\n",
      "Processing image: IMG_4563.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1815, 344, 3183, 2305\n",
      "Processing image: IMG_4948.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 240, 1044, 2357, 2717\n",
      "Bounding box: 1058, 1480, 1832, 2220\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4926.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1330, 57, 2623, 1848\n",
      "Bounding box: 1625, 818, 2177, 1398\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4966.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 405, 1260, 1993, 2566\n",
      "Bounding box: 1069, 1657, 1622, 2213\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4610.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1345, 445, 2687, 2188\n",
      "Processing image: IMG_4572.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 970, 202, 2528, 2364\n",
      "Processing image: IMG_4953.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 470, 1379, 2650, 3093\n",
      "Bounding box: 1340, 1812, 2078, 2535\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4962.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 396, 1638, 1802, 2784\n",
      "Bounding box: 991, 1958, 1477, 2452\n",
      "File already exists, saving with _1\n",
      "Bounding box: 392, 1635, 2015, 2786\n",
      "File already exists, saving with _2\n",
      "Processing image: IMG_4559.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 2372, 448, 3689, 2362\n",
      "Processing image: IMG_4883.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1091, 201, 2763, 2514\n",
      "Bounding box: 1527, 1067, 2140, 1745\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4637.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1285, 428, 2671, 2406\n",
      "Processing image: IMG_4920.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1023, 1176, 2680, 2868\n",
      "Bounding box: 1474, 1895, 2150, 2461\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4579.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1713, 247, 2986, 2272\n",
      "Bounding box: 2148, 1100, 2655, 1704\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4560.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 2244, 368, 3584, 2324\n",
      "Bounding box: 2711, 1093, 3205, 1717\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4557.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 2330, 556, 3583, 2397\n",
      "Processing image: IMG_4574.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 836, 255, 2396, 2306\n",
      "Processing image: IMG_4886.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1018, 32, 2746, 2412\n",
      "Bounding box: 1470, 914, 2048, 1593\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4967.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 376, 947, 2044, 2347\n",
      "Bounding box: 1071, 1398, 1654, 1984\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4631.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1270, 550, 2789, 2437\n",
      "Processing image: IMG_4937.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 926, 577, 2730, 2794\n",
      "Bounding box: 1388, 1468, 2064, 2127\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4545.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1680, 648, 2843, 2317\n",
      "Processing image: IMG_4969.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 492, 492, 2372, 2172\n",
      "Bounding box: 1266, 1056, 1915, 1698\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4944.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 349, 1080, 2464, 2764\n",
      "Bounding box: 1170, 1518, 1937, 2260\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4605.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1353, 247, 2736, 2082\n",
      "Processing image: IMG_4873.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1247, 358, 2665, 2527\n",
      "Bounding box: 1601, 1235, 2256, 1933\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4951.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 328, 1080, 2449, 2779\n",
      "Bounding box: 1189, 1516, 1925, 2246\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4613.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1263, 645, 2544, 2293\n",
      "Processing image: IMG_4548.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1543, 432, 2750, 2188\n",
      "Processing image: IMG_4974.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 390, 470, 2497, 2228\n",
      "Bounding box: 1237, 1035, 1957, 1708\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4941.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 395, 916, 2530, 2690\n",
      "Bounding box: 1258, 1411, 2004, 2164\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4589.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1730, 340, 3068, 2345\n",
      "Processing image: IMG_4614.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1177, 631, 2454, 2273\n",
      "Processing image: IMG_4931.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1262, 936, 2645, 2762\n",
      "Bounding box: 1584, 1641, 2173, 2237\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4907.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1495, 500, 2695, 2237\n",
      "Bounding box: 1787, 1227, 2322, 1783\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4914.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 972, 443, 2820, 2926\n",
      "Bounding box: 1428, 1498, 2226, 2302\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4655.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1122, 605, 3192, 2217\n",
      "Processing image: IMG_4906.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1462, 295, 2764, 2295\n",
      "Bounding box: 1785, 1125, 2363, 1754\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4599.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1776, 484, 2946, 2272\n",
      "Processing image: IMG_4970.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1310, 980, 2000, 1641\n",
      "Bounding box: 509, 428, 2500, 2139\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4587.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1734, 344, 3075, 2368\n",
      "Processing image: IMG_4542.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1494, 499, 2645, 2150\n",
      "Processing image: IMG_4896.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1189, 239, 2661, 2542\n",
      "Bounding box: 1597, 1148, 2231, 1851\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4956.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 252, 943, 2671, 2811\n",
      "Bounding box: 1232, 1511, 1993, 2248\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4630.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1167, 469, 2680, 2330\n",
      "Processing image: IMG_4583.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1624, 191, 2978, 2290\n",
      "Bounding box: 2084, 1020, 2602, 1654\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4938.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 885, 633, 2666, 2812\n",
      "Bounding box: 1358, 1509, 2034, 2160\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4913.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1436, 206, 3113, 2519\n",
      "Bounding box: 1820, 1193, 2534, 1932\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4633.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1296, 423, 2771, 2395\n",
      "Processing image: IMG_4977.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 506, 834, 2410, 2429\n",
      "Bounding box: 1293, 1349, 1947, 2022\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4904.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1820, 239, 3198, 2639\n",
      "Bounding box: 2327, 1171, 2832, 1867\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4573.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 798, 266, 2359, 2318\n",
      "Processing image: IMG_4881.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1369, 370, 3010, 2656\n",
      "Bounding box: 1770, 1227, 2407, 1911\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4540.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1239, 629, 2416, 2304\n",
      "Processing image: IMG_4901.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1710, 42, 3066, 2540\n",
      "Bounding box: 2243, 1001, 2665, 1702\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4624.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1462, 484, 2922, 2384\n",
      "Processing image: IMG_4628.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1383, 336, 2841, 2237\n",
      "Processing image: IMG_4909.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1512, 548, 2719, 2301\n",
      "Bounding box: 1800, 1266, 2340, 1830\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4618.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 983, 3, 2732, 2312\n",
      "Bounding box: 1580, 965, 2350, 1765\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4983.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 354, 1134, 2989, 3089\n",
      "Bounding box: 1102, 1780, 1877, 2493\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4578.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1786, 306, 3049, 2317\n",
      "Bounding box: 2219, 1150, 2719, 1746\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4885.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1140, 46, 2838, 2412\n",
      "Bounding box: 1572, 936, 2165, 1618\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4611.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1353, 497, 2676, 2202\n",
      "Processing image: IMG_4884.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1133, 84, 2809, 2430\n",
      "Bounding box: 1556, 966, 2156, 1649\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4620.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 985, 277, 2793, 2670\n",
      "Bounding box: 1570, 1506, 2337, 2205\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4968.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 483, 695, 2250, 2239\n",
      "Bounding box: 1213, 1204, 1825, 1815\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4650.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1624, 1145, 2379, 1936\n",
      "Bounding box: 1038, 427, 2775, 2522\n",
      "File already exists, saving with _1\n",
      "Bounding box: 1036, 424, 2776, 2842\n",
      "File already exists, saving with _2\n",
      "Processing image: IMG_4897.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 882, 0, 2552, 2516\n",
      "Bounding box: 1444, 976, 2070, 1709\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4959.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 255, 957, 2934, 2995\n",
      "Bounding box: 1044, 1620, 1823, 2344\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4876.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1297, 420, 2707, 2554\n",
      "Bounding box: 1642, 1276, 2292, 1972\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4949.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 302, 1092, 2371, 2755\n",
      "Bounding box: 1109, 1531, 1862, 2258\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4911.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1368, 417, 2609, 2308\n",
      "Bounding box: 1679, 1182, 2239, 1789\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4550.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1345, 308, 2628, 2120\n",
      "Processing image: IMG_4654.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1674, 1160, 2431, 1963\n",
      "Bounding box: 1066, 442, 2817, 2549\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4984.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 162, 1020, 2961, 3075\n",
      "Bounding box: 970, 1693, 1788, 2425\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4536.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1452, 579, 2628, 2204\n",
      "Processing image: IMG_4565.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1619, 357, 3043, 2345\n",
      "Processing image: IMG_4950.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 286, 917, 2378, 2598\n",
      "Bounding box: 1136, 1352, 1875, 2081\n",
      "File already exists, saving with _1\n",
      "Bounding box: 281, 914, 2731, 2597\n",
      "File already exists, saving with _2\n",
      "Processing image: IMG_4952.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1284, 1706, 2019, 2429\n",
      "Bounding box: 419, 1288, 2577, 2981\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4889.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 794, 1, 2481, 2422\n",
      "Bounding box: 1231, 904, 1817, 1605\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4585.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1600, 284, 2933, 2338\n",
      "Processing image: IMG_4933.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1087, 1113, 2769, 3024\n",
      "Bounding box: 1472, 1876, 2141, 2529\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4596.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1816, 536, 3013, 2370\n",
      "Processing image: IMG_4922.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1087, 519, 2737, 2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1500, 1330, 2161, 1925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4965.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 445, 1619, 1928, 2838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 442, 1616, 2165, 2839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4932.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1190, 1023, 2666, 2917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1537, 1741, 2149, 2348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4644.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1730, 345, 3132, 2261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4900.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1461, 0, 2886, 2472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4649.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1658, 1111, 2424, 1918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1059, 348, 2865, 2827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1062, 350, 2864, 2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4890.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1372, 1095, 1987, 1797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 940, 203, 2624, 2612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4609.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1349, 374, 2698, 2144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4604.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1336, 173, 2731, 2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4543.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1618, 569, 2769, 2218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4544.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1764, 622, 2921, 2270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4567.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1331, 53, 2853, 2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4561.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1990, 377, 3326, 2327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4930.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1169, 866, 2439, 2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1471, 1541, 2031, 2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4899.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1838, 872, 2291, 1579\n",
      "Bounding box: 1185, 0, 2755, 2451\n",
      "File already exists, saving with _1\n",
      "Processing image: IMG_4566.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1465, 83, 2953, 2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4928.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1282, 682, 2505, 2352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1571, 1349, 2106, 1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4929.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1167, 862, 2434, 2566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1476, 1521, 2028, 2086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4597.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1805, 487, 2992, 2306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4880.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1294, 335, 2824, 2557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1655, 1202, 2298, 1889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4892.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 886, 363, 2468, 2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1266, 1279, 1968, 2025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4603.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 1325, 71, 2733, 1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4918.png\n",
      "final text_encoder_type: bert-base-uncased\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n",
      "Running model...\n",
      "Bounding box: 908, 790, 2723, 2865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding box: 1410, 1692, 2155, 2370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Write Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: IMG_4586.png\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device: '/tmp/tmpq_d0hkqy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m image_pil, image \u001b[39m=\u001b[39m load_image(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfilepath\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mimgPath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m \u001b[39m# load model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m model \u001b[39m=\u001b[39m load_model(config_file, checkpoint_path, cpu_only\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=166'>167</a>\u001b[0m \u001b[39m# set the text_threshold to None if token_spans is set.\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m \u001b[39mif\u001b[39;00m token_spans \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;32m/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(model_config_path, model_checkpoint_path, cpu_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     args \u001b[39m=\u001b[39m SLConfig\u001b[39m.\u001b[39;49mfromfile(model_config_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     args\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cpu_only \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jabv/Desktop/home-vision/dataset_generator/create_dataset_home2024_GrounDino.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     model \u001b[39m=\u001b[39m build_model(args)\n",
      "File \u001b[0;32m~/Desktop/home-vision/dataset_generator/groundingdino/util/slconfig.py:185\u001b[0m, in \u001b[0;36mSLConfig.fromfile\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfromfile\u001b[39m(filename):\n\u001b[0;32m--> 185\u001b[0m     cfg_dict, cfg_text \u001b[39m=\u001b[39m SLConfig\u001b[39m.\u001b[39;49m_file2dict(filename)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m SLConfig(cfg_dict, cfg_text\u001b[39m=\u001b[39mcfg_text, filename\u001b[39m=\u001b[39mfilename)\n",
      "File \u001b[0;32m~/Desktop/home-vision/dataset_generator/groundingdino/util/slconfig.py:81\u001b[0m, in \u001b[0;36mSLConfig._file2dict\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     79\u001b[0m check_file_exist(filename)\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.py\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mwith\u001b[39;00m tempfile\u001b[39m.\u001b[39;49mTemporaryDirectory() \u001b[39mas\u001b[39;00m temp_config_dir:\n\u001b[1;32m     82\u001b[0m         temp_config_file \u001b[39m=\u001b[39m tempfile\u001b[39m.\u001b[39mNamedTemporaryFile(\u001b[39mdir\u001b[39m\u001b[39m=\u001b[39mtemp_config_dir, suffix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.py\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m         temp_config_name \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mbasename(temp_config_file\u001b[39m.\u001b[39mname)\n",
      "File \u001b[0;32m/usr/lib/python3.8/tempfile.py:919\u001b[0m, in \u001b[0;36mTemporaryDirectory.__init__\u001b[0;34m(self, suffix, prefix, dir)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, suffix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, prefix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mdir\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 919\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m mkdtemp(suffix, prefix, \u001b[39mdir\u001b[39;49m)\n\u001b[1;32m    920\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalizer \u001b[39m=\u001b[39m _weakref\u001b[39m.\u001b[39mfinalize(\n\u001b[1;32m    921\u001b[0m         \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cleanup, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    922\u001b[0m         warn_message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImplicitly cleaning up \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.8/tempfile.py:497\u001b[0m, in \u001b[0;36mmkdtemp\u001b[0;34m(suffix, prefix, dir)\u001b[0m\n\u001b[1;32m    495\u001b[0m _sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mtempfile.mkdtemp\u001b[39m\u001b[39m\"\u001b[39m, file)\n\u001b[1;32m    496\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     _os\u001b[39m.\u001b[39;49mmkdir(file, \u001b[39m0o700\u001b[39;49m)\n\u001b[1;32m    498\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileExistsError\u001b[39;00m:\n\u001b[1;32m    499\u001b[0m     \u001b[39mcontinue\u001b[39;00m    \u001b[39m# try again\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: '/tmp/tmpq_d0hkqy'"
     ]
    }
   ],
   "source": [
    "pathtofiles = \"/home/jabv/Desktop/bolsas/\" #path to images to process\n",
    "resultspath = \"/home/jabv/Desktop/bolsas_precut\" #path to save results all ready processed and segmented images\n",
    "if not os.path.exists(resultspath):\n",
    "    os.makedirs(resultspath)\n",
    "\n",
    "def load_image(image_path):\n",
    "\n",
    "    image_pil = Image.open(image_path).convert(\"RGB\")  # load image\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.RandomResize([800], max_size=1333),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    image, _ = transform(image_pil, None)  # 3, h, w\n",
    "    return image_pil, image\n",
    "\n",
    "\n",
    "def load_model(model_config_path, model_checkpoint_path, cpu_only=False):\n",
    "    args = SLConfig.fromfile(model_config_path)\n",
    "    args.device = \"cuda\" if not cpu_only else \"cpu\"\n",
    "    model = build_model(args)\n",
    "    checkpoint = torch.load(model_checkpoint_path, map_location=\"cpu\")\n",
    "    load_res = model.load_state_dict(clean_state_dict(checkpoint[\"model\"]), strict=False)\n",
    "    print(load_res)\n",
    "    _ = model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_grounding_output(model, image, caption, box_threshold, text_threshold=None, with_logits=True, cpu_only=False, token_spans=None):\n",
    "    assert text_threshold is not None or token_spans is not None, \"text_threshould and token_spans should not be None at the same time!\"\n",
    "    caption = caption.lower()\n",
    "    caption = caption.strip()\n",
    "    if not caption.endswith(\".\"):\n",
    "        caption = caption + \".\"\n",
    "    device = \"cuda\" if not cpu_only else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        print(\"Running model...\")\n",
    "        outputs = model(image[None], captions=[caption])\n",
    "    logits = outputs[\"pred_logits\"].sigmoid()[0]  # (nq, 256)\n",
    "    boxes = outputs[\"pred_boxes\"][0]  # (nq, 4)\n",
    "\n",
    "    # filter output\n",
    "    if token_spans is None:\n",
    "        logits_filt = logits.cpu().clone()\n",
    "        boxes_filt = boxes.cpu().clone()\n",
    "        filt_mask = logits_filt.max(dim=1)[0] > box_threshold\n",
    "        logits_filt = logits_filt[filt_mask]  # num_filt, 256\n",
    "        boxes_filt = boxes_filt[filt_mask]  # num_filt, 4\n",
    "\n",
    "        # get phrase\n",
    "        tokenlizer = model.tokenizer\n",
    "        tokenized = tokenlizer(caption)\n",
    "        # build pred\n",
    "        pred_phrases = []\n",
    "        for logit, box in zip(logits_filt, boxes_filt):\n",
    "            pred_phrase = get_phrases_from_posmap(logit > text_threshold, tokenized, tokenlizer)\n",
    "            if with_logits:\n",
    "                pred_phrases.append(pred_phrase + f\"({str(logit.max().item())[:4]})\")\n",
    "            else:\n",
    "                pred_phrases.append(pred_phrase)\n",
    "    else:\n",
    "        # given-phrase mode\n",
    "        positive_maps = create_positive_map_from_span(\n",
    "            model.tokenizer(text_prompt),\n",
    "            token_span=token_spans\n",
    "        ).to(image.device) # n_phrase, 256\n",
    "\n",
    "        logits_for_phrases = positive_maps @ logits.T # n_phrase, nq\n",
    "        all_logits = []\n",
    "        all_phrases = []\n",
    "        all_boxes = []\n",
    "        for (token_span, logit_phr) in zip(token_spans, logits_for_phrases):\n",
    "            # get phrase\n",
    "            phrase = ' '.join([caption[_s:_e] for (_s, _e) in token_span])\n",
    "            # get mask\n",
    "            filt_mask = logit_phr > box_threshold\n",
    "            # filt box\n",
    "            all_boxes.append(boxes[filt_mask])\n",
    "            # filt logits\n",
    "            all_logits.append(logit_phr[filt_mask])\n",
    "            if with_logits:\n",
    "                logit_phr_num = logit_phr[filt_mask]\n",
    "                all_phrases.extend([phrase + f\"({str(logit.item())[:4]})\" for logit in logit_phr_num])\n",
    "            else:\n",
    "                all_phrases.extend([phrase for _ in range(len(filt_mask))])\n",
    "        boxes_filt = torch.cat(all_boxes, dim=0).cpu()\n",
    "        pred_phrases = all_phrases\n",
    "\n",
    "\n",
    "    return boxes_filt, pred_phrases\n",
    "\n",
    "# cfg\n",
    "config_file = \"/home/jabv/Desktop/home-vision/dataset_generator/groundingdino/config/GroundingDINO_SwinT_OGC.py\"  # change the path of the model config file\n",
    "\n",
    "#wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
    "checkpoint_path = \"/home/jabv/Desktop/home-vision/dataset_generator/groundingdino_swint_ogc.pth\"  # change the path of the model\n",
    "text_prompt = \"bannana\"\n",
    "output_dir = resultspath\n",
    "box_threshold = 0.3\n",
    "text_threshold = 0.25\n",
    "token_spans = None\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "sam_model = \"h\"\n",
    "\n",
    "#use sam model\n",
    "#wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
    "#wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\n",
    "if sam_model ==\"h\":\n",
    "  sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "  model_type = \"vit_h\"\n",
    "else:\n",
    "  sam_checkpoint = \"sam_vit_l_0b3195.pth\"\n",
    "  model_type = \"vit_l\"\n",
    "\n",
    "device = \"cuda\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "images=[]\n",
    "annotations=[]\n",
    "categories=[]\n",
    "\n",
    "img_id=0\n",
    "anno_id=0\n",
    "\n",
    "#check if results directory exists, else create it\n",
    "if not os.path.exists(resultspath):\n",
    "  os.makedirs(resultspath)\n",
    "\n",
    "#make a list of all the directories in the path\n",
    "pathtoimage = [f.path for f in os.scandir(pathtofiles) if f.is_dir()]\n",
    "\n",
    "#pathtoimage = os.listdir(pathtofiles)\n",
    "\n",
    "for filepath in pathtoimage:\n",
    "    imgPaths = os.listdir(filepath)\n",
    "    print(imgPaths)\n",
    "\n",
    "    i=0\n",
    "\n",
    "    for imgPath in imgPaths:\n",
    "        print(f\"Processing image: {imgPath}\")\n",
    "        img = imutils.resize(cv2.imread(f\"{filepath}/{imgPath}\"))\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "    #------------------------start grounding----------------------------------------------\n",
    "        #image_path = args.image_path\n",
    "\n",
    "        # load image\n",
    "        image_pil, image = load_image(f\"{filepath}/{imgPath}\")\n",
    "\n",
    "        # load model\n",
    "        model = load_model(config_file, checkpoint_path, cpu_only=False)\n",
    "\n",
    "        # set the text_threshold to None if token_spans is set.\n",
    "        if token_spans is not None:\n",
    "            text_threshold = None\n",
    "            print(\"Using token_spans. Set the text_threshold to None.\")\n",
    "\n",
    "        # run model\n",
    "        boxes_filt, pred_phrases = get_grounding_output(\n",
    "            model, image, text_prompt, box_threshold, text_threshold, cpu_only=False, token_spans=eval(f\"{token_spans}\")\n",
    "        )\n",
    "\n",
    "        #found bb dimensions\n",
    "\n",
    "        size = image_pil.size\n",
    "        pred_dict = {\n",
    "            \"boxes\": boxes_filt,\n",
    "            \"size\": [size[1], size[0]],  # H,W\n",
    "            \"labels\": pred_phrases,\n",
    "        }\n",
    "\n",
    "        H, W = pred_dict[\"size\"]\n",
    "        boxes = pred_dict[\"boxes\"]\n",
    "        labels = pred_dict[\"labels\"]\n",
    "        assert len(boxes) == len(labels), \"boxes and labels must have same length\"\n",
    "\n",
    "        draw = ImageDraw.Draw(image_pil)\n",
    "        mask = Image.new(\"L\", image_pil.size, 0)\n",
    "        mask_draw = ImageDraw.Draw(mask)\n",
    "\n",
    "        #change pil image to cv2 image\n",
    "        img = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "        img2 = img.copy()\n",
    "        # draw boxes and masks\n",
    "        for box, label in zip(boxes, labels):\n",
    "            # from 0..1 to 0..W, 0..H\n",
    "            box = box * torch.Tensor([W, H, W, H])\n",
    "            # from xywh to xyxy\n",
    "            box[:2] -= box[2:] / 2\n",
    "            box[2:] += box[:2]\n",
    "            # random color\n",
    "            color = tuple(np.random.randint(0, 255, size=1).tolist())\n",
    "            # draw\n",
    "            padding = 10\n",
    "            x0, y0, x1, y1 = box\n",
    "            x0, y0, x1, y1 = int(x0)-padding, int(y0)-padding, int(x1)+padding, int(y1)+padding\n",
    "\n",
    "            #validate if the bounding box is inside the image\n",
    "            if x0 < 0:\n",
    "                x0 = 0\n",
    "            if y0 < 0:\n",
    "                y0 = 0\n",
    "            if x1 > W:\n",
    "                x1 = W\n",
    "            if y1 > H:\n",
    "                y1 = H\n",
    "                \n",
    "            #draw rectangles\n",
    "            cv2.rectangle(img2, (x0, y0), (x1, y1), color, 2)\n",
    "\n",
    "            draw.rectangle([x0, y0, x1, y1], outline=color, width=6)\n",
    "            # draw.text((x0, y0), str(label), fill=color)\n",
    "\n",
    "            font = ImageFont.load_default()\n",
    "            if hasattr(font, \"getbbox\"):\n",
    "                bbox = draw.textbbox((x0, y0), str(label), font)\n",
    "            else:\n",
    "                w, h = draw.textsize(str(label), font)\n",
    "                bbox = (x0, y0, w + x0, y0 + h)\n",
    "            # bbox = draw.textbbox((x0, y0), str(label))\n",
    "            draw.rectangle(bbox, fill=color)\n",
    "            draw.text((x0, y0), str(label), fill=\"white\")\n",
    "\n",
    "            mask_draw.rectangle([x0, y0, x1, y1], fill=255, width=6)\n",
    "        \n",
    "    # ----------------End grounding ---------------------------------------------------------   \n",
    "        \n",
    "    # ----------------Start SAM--------------------------------------------------------------  \n",
    "            \n",
    "            class_name = filepath.split(\"/\")[-1]\n",
    "            #print x0, y0, x1, y1\n",
    "            print(f\"Bounding box: {x0}, {y0}, {x1}, {y1}\")\n",
    "\n",
    "            sam_bounding_box = np.array([x0, y0, x1, y1])\n",
    "            ran_sam = False\n",
    "            #run sam\n",
    "            if ran_sam == False:\n",
    "                predictor.set_image(img)\n",
    "                ran_sam = True\n",
    "\n",
    "            mask, _, _ = predictor.predict(\n",
    "                point_coords=None,\n",
    "                point_labels=None,\n",
    "                box=sam_bounding_box,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "\n",
    "            mask, _, _ = predictor.predict(box=sam_bounding_box, multimask_output=False)\n",
    "\n",
    "            #Make png mask\n",
    "            contours, _ = cv2.findContours(mask[0].astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # Your call to find the contours\n",
    "\n",
    "            # threshold input image using otsu thresholding as mask and refine with morphology\n",
    "            ret, pngmask = cv2.threshold(mask[0].astype(np.uint8), 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU) \n",
    "            kernel = np.ones((9,9), np.uint8)\n",
    "            pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_CLOSE, kernel)\n",
    "            pngmask = cv2.morphologyEx(pngmask, cv2.MORPH_OPEN, kernel)\n",
    "            result = img.copy()\n",
    "            result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "            result[:, :, 3] = pngmask                           \n",
    "\n",
    "    # ----------------End SAM-----------------------------------------------------------------  \n",
    "            #cv2.imwrite(f\"{resultspath}/groundingcv2_{imgPath}\", img2)\n",
    "\n",
    "            #image_pil.save(f\"{resultspath}/grounding_{imgPath}\")\n",
    "\n",
    "            if not os.path.exists(f\"{resultspath}/{class_name}\"):\n",
    "                os.mkdir(f\"{resultspath}/{class_name}\")\n",
    "\n",
    "            file_path = f\"{resultspath}/{class_name}/{imgPath[:-4]}.png\"\n",
    "            if os.path.exists(file_path):\n",
    "                if os.path.exists(f\"{resultspath}/{class_name}/{imgPath[:-4]}_1.png\"):\n",
    "                    print(\"File already exists, saving with _2\")\n",
    "                    cv2.imwrite(f\"{resultspath}/{class_name}/{imgPath[:-4]}_2.png\", result)\n",
    "                else:\n",
    "                    print(\"File already exists, saving with _1\")\n",
    "                    file_path = f\"{resultspath}/{class_name}/{imgPath[:-4]}_1.png\"\n",
    "\n",
    "            cv2.imwrite(file_path, result)\n",
    "            i=i+1\n",
    "            ran_sam = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gatos..png started\n",
      "aqui\n",
      "gatos..png done\n",
      "gatos._2.png started\n",
      "aqui\n",
      "gatos._2.png done\n",
      "gatos._1.png started\n",
      "aqui\n",
      "gatos._1.png done\n",
      "jarra3..png started\n",
      "aqui\n",
      "jarra3..png done\n",
      "jarra2..png started\n",
      "aqui\n",
      "jarra2..png done\n",
      "jarra1._2.png started\n",
      "aqui\n",
      "jarra1._2.png done\n",
      "jarra1._1.png started\n",
      "aqui\n",
      "jarra1._1.png done\n",
      "jarra1..png started\n",
      "aqui\n",
      "jarra1..png done\n",
      "lata.png started\n",
      "aqui\n",
      "lata.png done\n",
      "manzana1..png started\n",
      "aqui\n",
      "manzana1..png done\n",
      "manzana2._1.png started\n",
      "aqui\n",
      "manzana2._1.png done\n",
      "manzana1._2.png started\n",
      "aqui\n",
      "manzana1._2.png done\n",
      "manzana2._2.png started\n",
      "aqui\n",
      "manzana2._2.png done\n",
      "manzana1._1.png started\n",
      "aqui\n",
      "manzana1._1.png done\n",
      "manzana2..png started\n",
      "aqui\n",
      "manzana2..png done\n",
      "platano3..png started\n",
      "aqui\n",
      "platano3..png done\n",
      "platano3._1.png started\n",
      "aqui\n",
      "platano3._1.png done\n",
      "platano1._1.png started\n",
      "aqui\n",
      "platano1._1.png done\n",
      "platano2..png started\n",
      "aqui\n",
      "platano2..png done\n",
      "platano2._1.png started\n",
      "aqui\n",
      "platano2._1.png done\n",
      "platano1..png started\n",
      "aqui\n",
      "platano1..png done\n",
      "silla.png started\n",
      "aqui\n",
      "silla.png done\n",
      "silla_1.png started\n",
      "aqui\n",
      "silla_1.png done\n",
      "silla_2.png started\n",
      "aqui\n",
      "silla_2.png done\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "datasetpath = \"/home/jabv/Desktop/prueba/res/\"\n",
    "resultspath = \"/home/jabv/Desktop/prueba/DS_res/\"\n",
    "\n",
    "#create a result folder if it doesn't exist\n",
    "if not os.path.exists(resultspath):\n",
    "    os.makedirs(resultspath)\n",
    "    os.makedirs(resultspath+\"gatos/\")\n",
    "    os.makedirs(resultspath+\"jarra/\")\n",
    "    os.makedirs(resultspath+\"lata/\")\n",
    "    os.makedirs(resultspath+\"manzana/\")\n",
    "    os.makedirs(resultspath+\"platano/\")\n",
    "    os.makedirs(resultspath+\"silla/\")\n",
    "\n",
    "\n",
    "fg_folders = [\n",
    "    (\"gatos/\"),\n",
    "    (\"jarra/\"),\n",
    "    (\"lata/\"),\n",
    "    (\"manzana/\"),\n",
    "    (\"platano/\"),\n",
    "    (\"silla/\")\n",
    "]\n",
    "\n",
    "for folder in fg_folders:\n",
    "    for filename in os.listdir(f\"{datasetpath}{folder}\"):\n",
    "        try:\n",
    "            print(f\"{filename} started\")\n",
    "            myImage = Image.open(datasetpath+folder+filename)\n",
    "            black = Image.new('RGBA', myImage.size)\n",
    "            myImage = Image.composite(myImage, black, myImage)\n",
    "            #print(\"aqui\")\n",
    "            myCroppedImage = myImage.crop(myImage.getbbox())\n",
    "            myCroppedImage.save(f\"{resultspath}{folder}{filename}\")\n",
    "            print(f\"{filename} done\")\n",
    "        except:\n",
    "            print(f\"{filename} failed\")\n",
    "            continue\n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the three folders containing the images\n",
    "datasetPath = \"/home/jabv/Desktop/prueba/DS_res\"\n",
    "fg_folders = [\n",
    "    (f\"{datasetPath}/gatos/\",\"gatos\" ),\n",
    "    (f\"{datasetPath}/jarra/\",\"jarra\" ),\n",
    "    (f\"{datasetPath}/lata/\",\"lata\" ),\n",
    "    (f\"{datasetPath}/manzana/\",\"manzana\" ),\n",
    "    (f\"{datasetPath}/platano/\",\"platano\" ),\n",
    "    (f\"{datasetPath}/silla/\",\"silla\" )\n",
    "\n",
    "]\n",
    "bg_folder = \"/home/jabv/Desktop/prueba/bg/\"\n",
    "output_folder = \"/home/jabv/Desktop/prueba/ds_final/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gatos': 0, 'jarra': 1, 'lata': 2, 'manzana': 3, 'platano': 4, 'silla': 5}\n",
      "[{'id': 0, 'name': 'gatos'}, {'id': 1, 'name': 'jarra'}, {'id': 2, 'name': 'lata'}, {'id': 3, 'name': 'manzana'}, {'id': 4, 'name': 'platano'}, {'id': 5, 'name': 'silla'}]\n"
     ]
    }
   ],
   "source": [
    "objects_list = [\"gatos\", \"jarra\", \"lata\", \"manzana\", \"platano\", \"silla\"]\n",
    "annotations_ID = {}\n",
    "categories = []\n",
    "for i, object in enumerate(objects_list):\n",
    "    annotations_ID[object] = i\n",
    "    categories.append({\"id\": i, \"name\": object})\n",
    "\n",
    "print(annotations_ID)\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of files in each of the three folders\n",
    "fg_files = {}\n",
    "for folder, category in fg_folders:\n",
    "    fg_files[category] = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "trainfolder = output_folder + \"train/\"\n",
    "testfolder = output_folder + \"test/\"\n",
    "validfolder = output_folder + \"valid/\"\n",
    "os.mkdir(trainfolder)\n",
    "os.mkdir(testfolder)\n",
    "os.mkdir(validfolder)\n",
    "os.mkdir(trainfolder + \"images/\")\n",
    "os.mkdir(trainfolder + \"labels/\")\n",
    "os.mkdir(testfolder + \"images/\")\n",
    "os.mkdir(testfolder + \"labels/\")\n",
    "os.mkdir(validfolder + \"images/\")\n",
    "os.mkdir(validfolder + \"labels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "annotations=[]\n",
    "annotations2=[]\n",
    "annot_csv=[]\n",
    "\n",
    "img_id=int(0)\n",
    "anno_id=int(0)\n",
    "\n",
    "rescaling_min = 0.20\n",
    "rescaling_max = 0.70\n",
    "\n",
    "# Ratios at which these values will be modified\n",
    "brightness_ratio = 0.05\n",
    "saturation_ratio = 0.05\n",
    "hue_ratio = 0.02\n",
    "\n",
    "for j in range(20):\n",
    "    #create empty label file\n",
    "    with open(f'{trainfolder}labels/{img_id}.txt', 'w') as file:\n",
    "        pass\n",
    "    #select hramdomly how many objects will be in an image\n",
    "    num_objects = random.randint(0, 5)\n",
    "    #print(\"number of objects\",num_objects)\n",
    "    # Select random foreground images from the three folders, with replacement\n",
    "    fg_categories = random.choices(objects_list, k=num_objects)\n",
    "    \n",
    "    fg_files_selected = []\n",
    "    for category in fg_categories:\n",
    "        fg_files_selected.append([category,random.choice(fg_files[category])])\n",
    "    #print(\"seleccion\",fg_files_selected)\n",
    "    # Load the selected foreground images using Pillow\n",
    "    fg_imgs = []\n",
    "    for img in fg_files_selected:\n",
    "        folder = [f[0] for f in fg_folders if f[1] == img[0]][0]\n",
    "        fg_imgs.append([img[0],Image.open(folder + img[1]),folder+img[1]])\n",
    "\n",
    "    # Randomly resize and rotate the foreground images using Pillow's transform module\n",
    "    # img[0] is category, img[1] is image, img[2] is path\n",
    "    for img in fg_imgs:\n",
    "        fg_img=img[1]\n",
    "        angle = random.randint(-5, 5)\n",
    "        scale = random.uniform(rescaling_min, rescaling_max)\n",
    "        fg_img = fg_img.rotate(angle, resample=Image.BICUBIC, expand=True)\n",
    "        fg_img = fg_img.resize((int(fg_img.width * scale), int(fg_img.height * scale)))\n",
    "        fg_img = ImageEnhance.Brightness(fg_img).enhance(random.uniform(0.7, 1.3))\n",
    "        fg_img = ImageEnhance.Contrast(fg_img).enhance(random.uniform(0.9, 1.1))\n",
    "        fg_img = ImageEnhance.Color(fg_img).enhance(random.uniform(0.7, 1.3))\n",
    "        fg_img = fg_img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.0, 0.5)))\n",
    "\n",
    "\n",
    "        img[1] = fg_img\n",
    "\n",
    "    # Load the background image using Pillow\n",
    "    bg_files = os.listdir(bg_folder)\n",
    "    bg_file = random.choice(bg_files)\n",
    "    bg_img = Image.open(bg_folder + bg_file)\n",
    "\n",
    "    # Define the maximum overlap as a percentage\n",
    "    max_overlap_pct = 10\n",
    "\n",
    "    # Define an array to keep track of occupied areas\n",
    "    occupied = np.zeros((bg_img.height, bg_img.width))\n",
    "\n",
    "    for img in fg_imgs:\n",
    "        fg_img=img[1]\n",
    "\n",
    "        # Calculate the maximum overlap area\n",
    "        max_overlap_area = (fg_img.width * fg_img.height)\n",
    "\n",
    "        seg_img = img[1]\n",
    "\n",
    "\n",
    "        # Convert the image to a NumPy array\n",
    "        img_arr = np.array(seg_img)\n",
    "        # Create a binary mask of the non-transparent pixels\n",
    "        mask = img_arr[:, :, 3] != 0\n",
    "\n",
    "        # Convert the mask to a COCO format segmentation\n",
    "        segmentation = []\n",
    "        for i in range(mask.shape[0]):\n",
    "            for j in range(mask.shape[1]):\n",
    "                if mask[i, j]:\n",
    "                    segmentation.append(j)\n",
    "                    segmentation.append(i)\n",
    "        segmentation = [segmentation]\n",
    "\n",
    "        # Calculate the area of the segmentation\n",
    "        area = 0\n",
    "        for i in range(len(segmentation[0]) // 2):\n",
    "            x1 = segmentation[0][2 * i]\n",
    "            y1 = segmentation[0][2 * i + 1]\n",
    "            x2 = segmentation[0][(2 * i + 2) % len(segmentation[0])]\n",
    "            y2 = segmentation[0][(2 * i + 3) % len(segmentation[0])]\n",
    "            area += x1 * y2 - x2 * y1\n",
    "        area = abs(area) / 2\n",
    "        \n",
    "        # Draw the segmentation onto a copy of the original image\n",
    "        #image_copy = image.copy()\n",
    "        #cv2.fillPoly(image_copy, aux_segmentation, color=(0, 255, 0))\n",
    "\n",
    "        # Display the image with segmentation overlay\n",
    "        #cv2.imshow('Image with Segmentation', image_copy)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "\n",
    "        # Calculate the maximum allowed position for the top-left corner\n",
    "        max_x = bg_img.width - fg_img.width\n",
    "        max_y = bg_img.height - fg_img.height\n",
    "        area = fg_img.width * fg_img.height\n",
    "\n",
    "        # Generate a random location until an unoccupied area is found that meets the overlap limit\n",
    "        total_area = bg_img.width * bg_img.height\n",
    "        overlap_area = total_area\n",
    "        \n",
    "        while overlap_area / area > max_overlap_pct / 100:\n",
    "            try:\n",
    "                x = random.randint(0, max_x)\n",
    "                y = random.randint(0, max_y)\n",
    "            except:\n",
    "                x = random.randint(0, abs(max_x))\n",
    "                y = random.randint(0, abs(max_y))\n",
    "\n",
    "            # Calculate the overlap area\n",
    "            overlap_area = np.sum(occupied[y:y+fg_img.height, x:x+fg_img.width])\n",
    "\n",
    "            # Check if the area is unoccupied and the overlap limit is not exceeded\n",
    "            if (max_overlap_area) >= overlap_area/10:\n",
    "                break\n",
    "            if i==10:\n",
    "                continue\n",
    "        \n",
    "        for i in range(0, len(segmentation[0])):\n",
    "            if i % 2:\n",
    "                segmentation[0][i]=int(segmentation[0][i]+y)\n",
    "            else :\n",
    "                segmentation[0][i]=int(segmentation[0][i]+x)\n",
    "        # Update the occupied array\n",
    "        occupied[y:y+fg_img.height, x:x+fg_img.width] = 1\n",
    "\n",
    "        bg_img.paste(fg_img, (x, y), fg_img)\n",
    "        x_center_ann = (x+fg_img.width/2) / bg_img.width\n",
    "        y_center_ann = (y+fg_img.height/2) / bg_img.height\n",
    "        width_ann = fg_img.width / bg_img.width\n",
    "        height_ann = fg_img.height / bg_img.height\n",
    "        with open(f'{trainfolder}labels/{img_id}.txt', 'a') as f:\n",
    "            f.write(f\"{annotations_ID[img[0]]} {x_center_ann} {y_center_ann} {width_ann} {height_ann}\\n\")\n",
    "        annotations2.append({\"id\": anno_id,\"image_id\": img_id,\"category_id\": annotations_ID[img[0]],\"bbox\": [x, y, fg_img.width, fg_img.height],\"segmentation\": segmentation,\"area\": area,\"iscrowd\": 0})\n",
    "        annotations.append({\"id\": anno_id,\"image_id\": img_id,\"category_id\": annotations_ID[img[0]],\"bbox\": [x, y, fg_img.width, fg_img.height],\"segmentation\": [],\"area\": fg_img.height*fg_img.width,\"iscrowd\": 0})\n",
    "        annot_csv.append([\"TRAIN\", output_folder + str(img_id)+\".jpg\", img[0], x/bg_img.width, y/bg_img.height,\"\",\"\",(x+fg_img.width)/bg_img.width, (y+fg_img.height)/bg_img.height])\n",
    "        anno_id=anno_id+1\n",
    "        #draw = ImageDraw.Draw(bg_img)\n",
    "        #fdraw.rectangle((x, y, x+fg_img.width, y+fg_img.height), outline='red', width=3)\n",
    "    bg_img.save(f\"{trainfolder}images/\"+str(img_id)+\".jpg\", quality=100)\n",
    "    images.append({\"id\": img_id, \"file_name\": str(img_id)+\".jpg\",\"height\": bg_img.height,\"width\": bg_img.width})\n",
    "    img_id=img_id+1\n",
    "    #print(img_id)\n",
    "\n",
    "#making data.yaml\n",
    "data = dict(\n",
    "    train = f\"{trainfolder}images\",\n",
    "    val = f\"{validfolder}images\",\n",
    "    test = f\"{validfolder}images\",\n",
    "    nc = len(annotations_ID),\n",
    "    names = list(annotations_ID.keys())\n",
    "    )\n",
    "#storing\n",
    "with open(f'{output_folder}data.yaml', 'w') as outfile:\n",
    "    yaml.dump(data, outfile, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SplitTrainValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "validation = 0.1\n",
    "test = 0.1\n",
    "\n",
    "# Assumes test has 100% of data\n",
    "output_folder = \"/home/jabv/Desktop/prueba/ds_final/\"\n",
    "trainfolder = output_folder + \"train/\"\n",
    "trainfolderimgs = trainfolder + \"images/\"\n",
    "trainfolderlabels = trainfolder + \"labels/\"\n",
    "testfolder = output_folder + \"test/\"\n",
    "testfolderimgs = testfolder + \"images/\"\n",
    "testfolderlabels = testfolder + \"labels/\"\n",
    "validfolder = output_folder + \"valid/\"\n",
    "validfolderimgs = validfolder + \"images/\"\n",
    "validfolderlabels = validfolder + \"labels/\"\n",
    "\n",
    "fullSize = len(os.listdir(trainfolderimgs))\n",
    "validSize = int(fullSize * validation)\n",
    "testSize = int(fullSize * test)\n",
    "\n",
    "for i in range(validSize):\n",
    "    filelist = os.listdir(trainfolderimgs)\n",
    "    #randomize file list, to not pick files in order\n",
    "    random.shuffle(filelist)\n",
    "    filetomove = filelist[i]\n",
    "    #take out .jpg, .png, etc\n",
    "    filetomovename = filetomove[:-4]\n",
    "    #move images\n",
    "    shutil.move(f\"{trainfolderimgs}{filetomove}\", f\"{validfolderimgs}{filetomove}\")\n",
    "    #move labels\n",
    "    shutil.move(f\"{trainfolderlabels}{filetomovename}.txt\", f\"{validfolderlabels}{filetomovename}.txt\")\n",
    "for i in range(testSize):\n",
    "    filetomove = os.listdir(trainfolderimgs)[i]\n",
    "    #take out .jpg, .png, etc\n",
    "    filetomovename = filetomove[:-4]\n",
    "    #move images\n",
    "    shutil.move(f\"{trainfolderimgs}{filetomove}\", f\"{testfolderimgs}{filetomove}\")\n",
    "    #move labels\n",
    "    shutil.move(f\"{trainfolderlabels}{filetomovename}.txt\", f\"{testfolderlabels}{filetomovename}.txt\")\n",
    "\n",
    "#Validation\n",
    "print(f\"Train size is now: {len(os.listdir(trainfolderimgs))}\")\n",
    "print(f\"Validation size is now: {len(os.listdir(validfolderimgs))}\")\n",
    "print(f\"Test size is now: {len(os.listdir(testfolderimgs))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
